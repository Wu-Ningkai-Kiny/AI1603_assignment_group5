{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5cd2807c",
   "metadata": {},
   "source": [
    "# 基于PyTorch的模型\n",
    "**注意：本文件为本小组对比探究用例，并非主要的探究内容，少部分内容由AI生成**\n",
    "\n",
    "为保证代码运行的稳定性，建议您使用以下版本的python及其库：\n",
    "\n",
    "| 名称 | python | numpy | pandas | matplotlib | seaborn | torch | sklearn |\n",
    "| ------- | ------- | ------- | ------- | ------- | ------- | ------- | ------- |\n",
    "| 版本号 | 3.11.13 | 2.3.1 | 2.3.1 | 3.10.3 | 0.13.2 | 2.7.1+cpu | 1.7.0 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "239d22ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "import joblib\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.font_manager import FontProperties\n",
    "import warnings\n",
    "\n",
    "# 忽略警告\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "038bce8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置中文字体支持\n",
    "try:\n",
    "    font = FontProperties(fname=r'C:\\Windows\\Fonts\\simhei.ttf', size=12)  # Windows\n",
    "    plt.rcParams['font.sans-serif'] = ['SimHei']  # 用来正常显示中文标签\n",
    "    plt.rcParams['axes.unicode_minus'] = False  # 用来正常显示负号\n",
    "except:\n",
    "    try:\n",
    "        font = FontProperties(fname='/System/Library/Fonts/PingFang.ttc', size=12)  # macOS\n",
    "    except:\n",
    "        print(\"警告: 中文字体设置失败，图表可能无法显示中文\")\n",
    "\n",
    "# 设置随机种子确保可复现性\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be316520",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据上传\n",
    "def load_data(file_path, is_train=True):\n",
    "    data = pd.read_csv(file_path, header=0)\n",
    "    if is_train:\n",
    "        ids = data.iloc[:, 0].values\n",
    "        labels = data.iloc[:, 1].values\n",
    "        features = data.iloc[:, 2:].values\n",
    "        print(f\"训练集加载完成: {features.shape[0]}个样本, {features.shape[1]}个特征\")\n",
    "        return ids, features, labels\n",
    "    else:\n",
    "        ids = data.iloc[:, 0].values\n",
    "        features = data.iloc[:, 2:].values\n",
    "        print(f\"测试集加载完成: {features.shape[0]}个样本, {features.shape[1]}个特征\")\n",
    "        return ids, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f27af92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据预处理\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# 使用sklearn库对特征数据进行归一化\n",
    "def preprocess_features(features, scaler=None, fit_scaler=False):\n",
    "    # 需要创建新的归一化数据\n",
    "    if fit_scaler:\n",
    "        scaler = StandardScaler()\n",
    "        scaled_features = scaler.fit_transform(features)\n",
    "        return scaled_features, scaler\n",
    "    # 已经有归一化数据了\n",
    "    else:\n",
    "        scaled_features = scaler.transform(features)\n",
    "        return scaled_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac92a265",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建数据集\n",
    "def create_datasets(features, labels, test_size=0.2):\n",
    "    # 转换为Tensor，方便使用torch\n",
    "    features_tensor = torch.tensor(features, dtype=torch.float32)\n",
    "    labels_tensor = torch.tensor(labels, dtype=torch.float32).unsqueeze(1)\n",
    "    \n",
    "    full_dataset = TensorDataset(features_tensor, labels_tensor)\n",
    "    \n",
    "    # 分割训练集和验证集（train_set和val_set）\n",
    "    train_size = int((1 - test_size) * len(full_dataset))\n",
    "    val_size = len(full_dataset) - train_size\n",
    "    train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n",
    "    \n",
    "    return train_dataset, val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6fed5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 多层感知机前向传播\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_layers=[128, 64], dropout_rate=0.3):\n",
    "        super(MLP, self).__init__()\n",
    "        layers = []\n",
    "        \n",
    "        # 添加隐藏层\n",
    "        for hidden_size in hidden_layers:\n",
    "            # 全连接层\n",
    "            layers.append(nn.Linear(input_size, hidden_size))\n",
    "            # 激活函数\n",
    "            layers.append(nn.LeakyReLU(0.1))\n",
    "            # 正则化层（防止过拟合）\n",
    "            layers.append(nn.Dropout(dropout_rate))\n",
    "            input_size = hidden_size\n",
    "        \n",
    "        # 输出层\n",
    "        layers.append(nn.Linear(input_size, 1))\n",
    "        # 将输出压缩到0~1，便于判断结果\n",
    "        layers.append(nn.Sigmoid())\n",
    "        \n",
    "        # 顺序排列各层，形成多层感知机\n",
    "        self.model = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7de0932e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练函数\n",
    "# 可以修改epoch和learning-rate\n",
    "def train_model(model, train_loader, val_loader, epochs=50, lr=0.001):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    \n",
    "    criterion = nn.BCELoss() # 损失函数，二元交叉熵损失函数，用于二分类问题\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr) # 优化器\n",
    "    \n",
    "    # 记录训练历史\n",
    "    history = {\n",
    "        'train_loss': [],\n",
    "        'val_loss': [],\n",
    "        'val_acc': [],\n",
    "        'val_f1': []\n",
    "    }\n",
    "    \n",
    "    best_val_acc = 0.0\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        \n",
    "        # 训练\n",
    "        for inputs, targets in train_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            \n",
    "            optimizer.zero_grad() # 清空梯度\n",
    "            outputs = model(inputs) # 前向传播\n",
    "            loss = criterion(outputs, targets) # 计算损失函数值\n",
    "            loss.backward() # 计算梯度\n",
    "            optimizer.step() # 更新参数权重\n",
    "            # with torch.no_grad():\n",
    "            #     for param in model.parameters():\n",
    "            #         if param.grad is not None:\n",
    "            #             param -= lr * param.grad\n",
    "            \n",
    "            train_loss += loss.item() * inputs.size(0)\n",
    "        \n",
    "        # 验证\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        all_preds = []\n",
    "        all_targets = []\n",
    "        \n",
    "        # 禁用梯度\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in val_loader:\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                \n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "                \n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "                preds = (outputs > 0.5).float()\n",
    "                \n",
    "                # .cpu将数据从GPU转到CPU\n",
    "                # .numpy将张量转化成数组\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_targets.extend(targets.cpu().numpy())\n",
    "        \n",
    "        # 计算指标\n",
    "        # 模型在训练集上的平均损失值\n",
    "        train_loss = train_loss / len(train_loader.dataset)\n",
    "        # 模型在验证集上的平均损失值\n",
    "        val_loss = val_loss / len(val_loader.dataset)\n",
    "        # 准确率：模型在验证机上的正确预测的比例\n",
    "        val_acc = accuracy_score(all_targets, all_preds)\n",
    "        # 精确率和召回率的调和平均数（综合判断精确率和召回率）\n",
    "        val_f1 = f1_score(all_targets, all_preds)\n",
    "        \n",
    "        # 记录\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_acc'].append(val_acc)\n",
    "        history['val_f1'].append(val_f1)\n",
    "        \n",
    "        # 保存最佳模型\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            torch.save(model.state_dict(), 'best_model.pth')\n",
    "            # 保存验证集预测结果用于混淆矩阵\n",
    "            np.save('val_targets.npy', np.array(all_targets))\n",
    "            np.save('val_preds.npy', np.array(all_preds))\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{epochs} | \"\n",
    "              f\"Train Loss: {train_loss:.4f} | \"\n",
    "              f\"Val Loss: {val_loss:.4f} | \"\n",
    "              f\"Val Acc: {val_acc:.4f} | \"\n",
    "              f\"Val F1: {val_f1:.4f}\")\n",
    "    \n",
    "    print(f\"训练完成，最佳验证准确率: {best_val_acc:.4f}\")\n",
    "    \n",
    "    # 绘制训练曲线\n",
    "    plot_training_history(history)\n",
    "    \n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16a7ab9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预测函数（同训练函数）\n",
    "def predict(model, test_features, batch_size=512):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    # numpy数组转化成pytorch张量\n",
    "    test_tensor = torch.tensor(test_features, dtype=torch.float32)\n",
    "    test_loader = DataLoader(test_tensor, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    all_preds = []\n",
    "    all_probs = [] # 原始可能性（0~1之间）\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs in test_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model(inputs)\n",
    "            preds = (outputs > 0.5).float()\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_probs.extend(outputs.cpu().numpy())\n",
    "    \n",
    "    return np.array(all_preds).flatten(), np.array(all_probs).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c00970a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存预测结果\n",
    "def save_predictions(test_ids, predictions, output_file='submission.csv'):\n",
    "    # 创建结果DataFrame\n",
    "    result_df = pd.DataFrame({\n",
    "        'id': test_ids,\n",
    "        'win': predictions.astype(int)  # 转换为整数类型\n",
    "    })\n",
    "    \n",
    "    # 保存到csv文件\n",
    "    result_df.to_csv(output_file, index=False)\n",
    "    print(f\"预测结果已保存至: {output_file}\")\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf98463c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可视化部分（纯AI）\n",
    "def plot_training_history(history):\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    # 损失值部分\n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.plot(history['train_loss'], label='训练损失')\n",
    "    plt.plot(history['val_loss'], label='验证损失')\n",
    "    plt.title('训练和验证损失', fontsize=14)\n",
    "    plt.xlabel('训练轮次', fontsize=12)\n",
    "    plt.ylabel('损失', fontsize=12)\n",
    "    plt.legend()\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # 准确率曲线\n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.plot(history['val_acc'], label='验证准确率', color='green')\n",
    "    plt.title('验证准确率', fontsize=14)\n",
    "    plt.xlabel('训练轮次', fontsize=12)\n",
    "    plt.ylabel('准确率', fontsize=12)\n",
    "    plt.legend()\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # F1分数曲线\n",
    "    plt.subplot(2, 2, 3)\n",
    "    plt.plot(history['val_f1'], label='验证F1分数', color='purple')\n",
    "    plt.title('验证F1分数', fontsize=14)\n",
    "    plt.xlabel('训练轮次', fontsize=12)\n",
    "    plt.ylabel('F1分数', fontsize=12)\n",
    "    plt.legend()\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # 组合图\n",
    "    plt.subplot(2, 2, 4)\n",
    "    plt.plot(history['val_acc'], label='准确率', color='green')\n",
    "    plt.plot(history['val_f1'], label='F1分数', color='purple')\n",
    "    plt.title('验证集性能指标', fontsize=14)\n",
    "    plt.xlabel('训练轮次', fontsize=12)\n",
    "    plt.ylabel('分数', fontsize=12)\n",
    "    plt.legend()\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('training_history.SVG', dpi=300)\n",
    "    plt.close()\n",
    "    print(\"训练历史图表已保存为 training_history.SVG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6bdc3392",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 绘制混淆矩阵\n",
    "def plot_confusion_matrix(y_true, y_pred, classes=['失败', '胜利']):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    \n",
    "    # import seaborn as sns\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=classes, yticklabels=classes,\n",
    "                annot_kws={\"size\": 16, \"weight\": \"bold\"})\n",
    "    \n",
    "    plt.title('混淆矩阵', fontsize=18)\n",
    "    plt.xlabel('预测标签', fontsize=14)\n",
    "    plt.ylabel('真实标签', fontsize=14)\n",
    "    \n",
    "    # 添加性能指标\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    plt.text(0.5, -0.15, \n",
    "             f'准确率: {accuracy:.4f} | F1分数: {f1:.4f}',\n",
    "             ha='center', va='center', transform=plt.gca().transAxes,\n",
    "             fontsize=12, bbox=dict(facecolor='white', alpha=0.8))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('confusion_matrix.SVG', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(\"混淆矩阵已保存为 confusion_matrix.SVG\")\n",
    "    return cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "76e6117f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 绘制预测分布\n",
    "def plot_prediction_distribution(predictions, probs=None):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # 预测结果分布\n",
    "    plt.subplot(1, 2, 1)\n",
    "    win_counts = pd.Series(predictions).value_counts()\n",
    "    win_counts.plot(kind='bar', color=['#ff9999', '#66b3ff'])\n",
    "    plt.title('预测结果分布', fontsize=14)\n",
    "    plt.xlabel('胜负结果', fontsize=12)\n",
    "    plt.ylabel('数量', fontsize=12)\n",
    "    plt.xticks([0, 1], ['失败', '胜利'], rotation=0)\n",
    "    \n",
    "    # 添加百分比标签\n",
    "    total = len(predictions)\n",
    "    for i, count in enumerate(win_counts):\n",
    "        plt.text(i, count + total*0.01, f'{count/total:.1%}', \n",
    "                 ha='center', fontsize=12)\n",
    "    \n",
    "    # 预测概率分布\n",
    "    if probs is not None:\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.hist(probs, bins=50, color='#88cc88', alpha=0.7)\n",
    "        plt.title('预测概率分布', fontsize=14)\n",
    "        plt.xlabel('胜利概率', fontsize=12)\n",
    "        plt.ylabel('样本数量', fontsize=12)\n",
    "        plt.axvline(0.5, color='r', linestyle='--', alpha=0.7)\n",
    "        plt.text(0.52, plt.ylim()[1]*0.9, '决策边界', color='r')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('prediction_distribution.SVG', dpi=300)\n",
    "    plt.close()\n",
    "    print(\"预测分布图表已保存为 prediction_distribution.SVG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b99f6ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 主程序部分\n",
    "TRAIN_PATH = 'train.csv'\n",
    "TEST_PATH = 'test_template.csv'\n",
    "OUTPUT_FILE = 'submission.csv'\n",
    "SCALER_FILE = 'scaler.pkl' # 标准化数据\n",
    "\n",
    "# 此处可以调整参数\n",
    "BATCH_SIZE = 256\n",
    "EPOCHS = 50\n",
    "HIDDEN_LAYERS = [256, 128, 64]  # 隐藏层结构\n",
    "DROPOUT_RATE = 0.4\n",
    "LEARNING_RATE = 0.0005\n",
    "TEST_SIZE = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e3f47b3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "开始训练阶段\n",
      "--------------------------------------------------\n",
      "训练集加载完成: 144000个样本, 30个特征\n",
      "Epoch 1/50 | Train Loss: 0.4173 | Val Loss: 0.3572 | Val Acc: 0.8339 | Val F1: 0.8336\n",
      "Epoch 2/50 | Train Loss: 0.3718 | Val Loss: 0.3514 | Val Acc: 0.8385 | Val F1: 0.8356\n",
      "Epoch 3/50 | Train Loss: 0.3654 | Val Loss: 0.3479 | Val Acc: 0.8386 | Val F1: 0.8361\n",
      "Epoch 4/50 | Train Loss: 0.3599 | Val Loss: 0.3458 | Val Acc: 0.8400 | Val F1: 0.8343\n",
      "Epoch 5/50 | Train Loss: 0.3578 | Val Loss: 0.3443 | Val Acc: 0.8402 | Val F1: 0.8386\n",
      "Epoch 6/50 | Train Loss: 0.3551 | Val Loss: 0.3430 | Val Acc: 0.8397 | Val F1: 0.8397\n",
      "Epoch 7/50 | Train Loss: 0.3531 | Val Loss: 0.3409 | Val Acc: 0.8410 | Val F1: 0.8398\n",
      "Epoch 8/50 | Train Loss: 0.3521 | Val Loss: 0.3414 | Val Acc: 0.8418 | Val F1: 0.8402\n",
      "Epoch 9/50 | Train Loss: 0.3496 | Val Loss: 0.3395 | Val Acc: 0.8429 | Val F1: 0.8384\n",
      "Epoch 10/50 | Train Loss: 0.3484 | Val Loss: 0.3381 | Val Acc: 0.8415 | Val F1: 0.8407\n",
      "Epoch 11/50 | Train Loss: 0.3465 | Val Loss: 0.3367 | Val Acc: 0.8442 | Val F1: 0.8394\n",
      "Epoch 12/50 | Train Loss: 0.3461 | Val Loss: 0.3361 | Val Acc: 0.8455 | Val F1: 0.8407\n",
      "Epoch 13/50 | Train Loss: 0.3452 | Val Loss: 0.3357 | Val Acc: 0.8438 | Val F1: 0.8409\n",
      "Epoch 14/50 | Train Loss: 0.3447 | Val Loss: 0.3355 | Val Acc: 0.8463 | Val F1: 0.8444\n",
      "Epoch 15/50 | Train Loss: 0.3433 | Val Loss: 0.3336 | Val Acc: 0.8460 | Val F1: 0.8408\n",
      "Epoch 16/50 | Train Loss: 0.3426 | Val Loss: 0.3337 | Val Acc: 0.8448 | Val F1: 0.8444\n",
      "Epoch 17/50 | Train Loss: 0.3415 | Val Loss: 0.3328 | Val Acc: 0.8474 | Val F1: 0.8431\n",
      "Epoch 18/50 | Train Loss: 0.3409 | Val Loss: 0.3321 | Val Acc: 0.8470 | Val F1: 0.8435\n",
      "Epoch 19/50 | Train Loss: 0.3410 | Val Loss: 0.3315 | Val Acc: 0.8465 | Val F1: 0.8416\n",
      "Epoch 20/50 | Train Loss: 0.3402 | Val Loss: 0.3320 | Val Acc: 0.8474 | Val F1: 0.8434\n",
      "Epoch 21/50 | Train Loss: 0.3390 | Val Loss: 0.3304 | Val Acc: 0.8475 | Val F1: 0.8439\n",
      "Epoch 22/50 | Train Loss: 0.3387 | Val Loss: 0.3309 | Val Acc: 0.8471 | Val F1: 0.8434\n",
      "Epoch 23/50 | Train Loss: 0.3389 | Val Loss: 0.3308 | Val Acc: 0.8467 | Val F1: 0.8461\n",
      "Epoch 24/50 | Train Loss: 0.3376 | Val Loss: 0.3298 | Val Acc: 0.8494 | Val F1: 0.8450\n",
      "Epoch 25/50 | Train Loss: 0.3359 | Val Loss: 0.3299 | Val Acc: 0.8495 | Val F1: 0.8467\n",
      "Epoch 26/50 | Train Loss: 0.3362 | Val Loss: 0.3298 | Val Acc: 0.8500 | Val F1: 0.8465\n",
      "Epoch 27/50 | Train Loss: 0.3357 | Val Loss: 0.3291 | Val Acc: 0.8504 | Val F1: 0.8464\n",
      "Epoch 28/50 | Train Loss: 0.3361 | Val Loss: 0.3281 | Val Acc: 0.8489 | Val F1: 0.8448\n",
      "Epoch 29/50 | Train Loss: 0.3356 | Val Loss: 0.3286 | Val Acc: 0.8499 | Val F1: 0.8462\n",
      "Epoch 30/50 | Train Loss: 0.3353 | Val Loss: 0.3279 | Val Acc: 0.8492 | Val F1: 0.8453\n",
      "Epoch 31/50 | Train Loss: 0.3357 | Val Loss: 0.3280 | Val Acc: 0.8490 | Val F1: 0.8445\n",
      "Epoch 32/50 | Train Loss: 0.3346 | Val Loss: 0.3287 | Val Acc: 0.8484 | Val F1: 0.8482\n",
      "Epoch 33/50 | Train Loss: 0.3350 | Val Loss: 0.3285 | Val Acc: 0.8485 | Val F1: 0.8447\n",
      "Epoch 34/50 | Train Loss: 0.3335 | Val Loss: 0.3273 | Val Acc: 0.8499 | Val F1: 0.8464\n",
      "Epoch 35/50 | Train Loss: 0.3333 | Val Loss: 0.3274 | Val Acc: 0.8494 | Val F1: 0.8452\n",
      "Epoch 36/50 | Train Loss: 0.3342 | Val Loss: 0.3273 | Val Acc: 0.8510 | Val F1: 0.8479\n",
      "Epoch 37/50 | Train Loss: 0.3342 | Val Loss: 0.3275 | Val Acc: 0.8494 | Val F1: 0.8456\n",
      "Epoch 38/50 | Train Loss: 0.3333 | Val Loss: 0.3271 | Val Acc: 0.8494 | Val F1: 0.8459\n",
      "Epoch 39/50 | Train Loss: 0.3333 | Val Loss: 0.3265 | Val Acc: 0.8506 | Val F1: 0.8467\n",
      "Epoch 40/50 | Train Loss: 0.3323 | Val Loss: 0.3262 | Val Acc: 0.8501 | Val F1: 0.8469\n",
      "Epoch 41/50 | Train Loss: 0.3330 | Val Loss: 0.3269 | Val Acc: 0.8500 | Val F1: 0.8462\n",
      "Epoch 42/50 | Train Loss: 0.3322 | Val Loss: 0.3270 | Val Acc: 0.8490 | Val F1: 0.8486\n",
      "Epoch 43/50 | Train Loss: 0.3318 | Val Loss: 0.3260 | Val Acc: 0.8498 | Val F1: 0.8465\n",
      "Epoch 44/50 | Train Loss: 0.3326 | Val Loss: 0.3265 | Val Acc: 0.8512 | Val F1: 0.8483\n",
      "Epoch 45/50 | Train Loss: 0.3318 | Val Loss: 0.3257 | Val Acc: 0.8510 | Val F1: 0.8468\n",
      "Epoch 46/50 | Train Loss: 0.3319 | Val Loss: 0.3261 | Val Acc: 0.8517 | Val F1: 0.8474\n",
      "Epoch 47/50 | Train Loss: 0.3309 | Val Loss: 0.3263 | Val Acc: 0.8529 | Val F1: 0.8517\n",
      "Epoch 48/50 | Train Loss: 0.3302 | Val Loss: 0.3253 | Val Acc: 0.8516 | Val F1: 0.8481\n",
      "Epoch 49/50 | Train Loss: 0.3312 | Val Loss: 0.3258 | Val Acc: 0.8508 | Val F1: 0.8477\n",
      "Epoch 50/50 | Train Loss: 0.3317 | Val Loss: 0.3261 | Val Acc: 0.8517 | Val F1: 0.8475\n",
      "训练完成，最佳验证准确率: 0.8529\n",
      "训练历史图表已保存为 training_history.SVG\n",
      "混淆矩阵已保存为 confusion_matrix.SVG\n"
     ]
    }
   ],
   "source": [
    "# 训练\n",
    "if os.path.exists(TRAIN_PATH):\n",
    "    print(\"-\"*50)\n",
    "    print(\"开始训练阶段\")\n",
    "    print(\"-\"*50)\n",
    "    \n",
    "    # 上传训练数据\n",
    "    _, train_features, train_labels = load_data(TRAIN_PATH, is_train=True)\n",
    "    \n",
    "    # 数据预处理\n",
    "    scaled_features, scaler = preprocess_features(train_features, fit_scaler=True)\n",
    "    \n",
    "    # 保存标准化数据\n",
    "    joblib.dump(scaler, SCALER_FILE)\n",
    "    \n",
    "    # 创建数据集\n",
    "    train_dataset, val_dataset = create_datasets(scaled_features, train_labels, test_size=TEST_SIZE)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n",
    "    \n",
    "    # 初始化模型\n",
    "    input_size = scaled_features.shape[1]\n",
    "    model = MLP(input_size, HIDDEN_LAYERS, DROPOUT_RATE)\n",
    "    \n",
    "    # 训练模型\n",
    "    trained_model, history = train_model(\n",
    "        model,\n",
    "        train_loader,\n",
    "        val_loader,\n",
    "        epochs=EPOCHS,\n",
    "        lr=LEARNING_RATE\n",
    "    )\n",
    "    \n",
    "    # 绘制混淆矩阵\n",
    "    try:\n",
    "        y_true = np.load('val_targets.npy')\n",
    "        y_pred = np.load('val_preds.npy')\n",
    "        cm = plot_confusion_matrix(y_true, y_pred)\n",
    "    except Exception as e:\n",
    "        print(f\"绘制混淆矩阵时出错: {e}\")\n",
    "else:\n",
    "    print(f\"训练文件 {TRAIN_PATH} 不存在\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f1652375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------\n",
      "开始预测阶段\n",
      "--------------------------------------------------\n",
      "测试集加载完成: 36000个样本, 30个特征\n",
      "已加载最佳模型参数\n",
      "预测结果已保存至: submission.csv\n",
      "预测结果分布: 胜率 49.86% | 负率 50.14%\n",
      "预测分布图表已保存为 prediction_distribution.SVG\n"
     ]
    }
   ],
   "source": [
    "# 预测\n",
    "if os.path.exists(TEST_PATH):\n",
    "    print(\"\\n\" + \"-\"*50)\n",
    "    print(\"开始预测阶段\")\n",
    "    print(\"-\"*50)\n",
    "    \n",
    "    # 上传测试数据\n",
    "    test_ids, test_features = load_data(TEST_PATH, is_train=False)\n",
    "    \n",
    "    # 加载标准化数据\n",
    "    if os.path.exists(SCALER_FILE):\n",
    "        scaler = joblib.load(SCALER_FILE)\n",
    "    else:\n",
    "        print(\"标准化器文件不存在\")\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(test_features)\n",
    "    \n",
    "    # 预处理测试数据\n",
    "    scaled_test_features = preprocess_features(test_features, scaler)\n",
    "    \n",
    "    # 初始化模型\n",
    "    input_size = scaled_test_features.shape[1]\n",
    "    model = MLP(input_size, HIDDEN_LAYERS, DROPOUT_RATE)\n",
    "    \n",
    "    # 加载最佳模型\n",
    "    if os.path.exists('best_model.pth'):\n",
    "        model.load_state_dict(torch.load('best_model.pth'))\n",
    "        print(\"已加载最佳模型参数\")\n",
    "    else:\n",
    "        print(\"未找到训练好的模型参数\")\n",
    "    \n",
    "    # 进行预测\n",
    "    predictions, probs = predict(model, scaled_test_features)\n",
    "    \n",
    "    # 保存结果\n",
    "    result_df = save_predictions(test_ids, predictions, OUTPUT_FILE)\n",
    "    \n",
    "    # 预测可视化部分\n",
    "    win_rate = np.mean(predictions) * 100\n",
    "    print(f\"预测结果分布: 胜率 {win_rate:.2f}% | 负率 {100-win_rate:.2f}%\")\n",
    "    \n",
    "    plot_prediction_distribution(predictions, probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe0bedc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
